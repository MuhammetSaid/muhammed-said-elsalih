# THE IMAM - Islamic Law Assistant (Mobile App)

**Subtitle:** Software and Artificial Intelligence

Modern teknolojilerle dini iÃ§erikleri birleÅŸtiren **The Imam**, kullanÄ±cÄ±larÄ±n Ä°slami kaynaklardan doÄŸru bilgilere hÄ±zlÄ±ca ulaÅŸmasÄ±nÄ± saÄŸlayan yenilikÃ§i bir mobil uygulama. Bu proje, **Retrieval Augmented Generation (RAG)** teknolojisini kullanarak, geleneksel dini metinleri yapay zeka ile buluÅŸturuyor. RAG, yapay zekanÄ±n bilgi kaynaklarÄ±ndan Ã¶ÄŸrenmesini ve kullanÄ±cÄ± sorularÄ±na kaynak gÃ¶stererek cevap vermesini saÄŸlayan bir yaklaÅŸÄ±m.

![The Imam Screenshot 1](images/the_imam_1.png)
![The Imam Screenshot 2](images/the_imam_2.png)
![The Imam Screenshot 3](images/the_imam_3.png)

## Proje HakkÄ±nda

**The Imam**, geniÅŸ bir Ä°slami kaynak koleksiyonunu vektÃ¶r tabanlÄ± arama sistemi ile indeksleyen, kullanÄ±cÄ± sorularÄ±na kaynak gÃ¶stererek cevap veren bir AI asistanÄ±. Uygulama, Kuran-Ä± Kerim, Tefsir kitaplarÄ±, FÄ±kÄ±h eserleri ve diÄŸer Ã¶nemli Ä°slami kaynaklarÄ± iÃ§eren kapsamlÄ± bir veritabanÄ±na sahiptir. OpenAI embeddings, ChromaDB ve LangChain/LangGraph gibi modern AI araÃ§larÄ± kullanÄ±larak geliÅŸtirilmiÅŸtir.

## Ana Ã–zellikler

- ğŸ¤– **AI Destekli Sohbet:** KullanÄ±cÄ± sorularÄ±na Kuran, tefsir, fÄ±kÄ±h ve diÄŸer Ä°slami kaynaklardan cevap veren akÄ±llÄ± asistan
- ğŸ“š **Kaynak GÃ¶sterimi:** Her cevap iÃ§in ilgili sure ve ayet referanslarÄ±
- ğŸ” **Semantic Search:** Anlama dayalÄ± vektÃ¶r aramasÄ± ile en ilgili iÃ§erikleri bulma
- ğŸ’¬ **Sohbet GeÃ§miÅŸi:** KullanÄ±cÄ± konuÅŸmalarÄ±nÄ± MySQL veritabanÄ±nda kaydetme ve yÃ¶netme
- ğŸ” **JWT Authentication:** Token tabanlÄ± gÃ¼venli kullanÄ±cÄ± kimlik doÄŸrulama
- ğŸ“± **Modern Mobil ArayÃ¼z:** Flutter ile geliÅŸtirilmiÅŸ kullanÄ±cÄ± dostu tasarÄ±m

---

![The Imam Screenshot 4](images/the_imam_4.png)
![The Imam Screenshot 5](images/the_imam_5.png)
![The Imam Screenshot 6](images/the_imam_6.png)
![The Imam Screenshot 7](images/the_imam_7.png)

---

## NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

The Imam, iki ana parÃ§adan oluÅŸuyor: **mobil uygulama** (Flutter ile geliÅŸtirildi) ve **sunucu tarafÄ±** (Python ile yazÄ±ldÄ±).

## Sunucu TarafÄ± (Backend)

Backend, **Python** ve **FastAPI** framework'Ã¼ ile geliÅŸtirildi. Sistem, kullanÄ±cÄ± sorularÄ±nÄ± alÄ±p, Ä°slami kaynaklarda arama yapÄ±yor ve cevaplarÄ± hazÄ±rlÄ±yor. Temel olarak ÅŸu adÄ±mlarÄ± izliyor:

1. **VektÃ¶rleÅŸtirme (Embedding):** TÃ¼m Ä°slami metinler (Kuran, tefsir, fÄ±kÄ±h vb.) OpenAI'nin text-embedding-3-large modeli kullanÄ±larak vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor. Bu iÅŸlem, metinleri sayÄ±sal deÄŸerlere Ã§evirerek bilgisayarÄ±n anlayabileceÄŸi forma getiriyor. Uzun metinler, RecursiveCharacterTextSplitter kullanÄ±larak yaklaÅŸÄ±k 50,000 karakterlik parÃ§alara bÃ¶lÃ¼nÃ¼yor. Bu parÃ§alama iÅŸlemi, OpenAI'nin token limitlerini aÅŸmamak ve daha verimli arama yapabilmek iÃ§in gerekli.

2. **VektÃ¶r VeritabanÄ± (ChromaDB):** VektÃ¶rleÅŸtirilmiÅŸ metinler, ChromaDB adÄ± verilen Ã¶zel bir vektÃ¶r veritabanÄ±na kaydediliyor. Her metin parÃ§asÄ±, hangi sure, ayet veya kitaptan geldiÄŸini gÃ¶steren metadata ile birlikte saklanÄ±yor.

3. **Semantic Search (Anlama DayalÄ± Arama):** KullanÄ±cÄ± bir soru sorduÄŸunda, sistem Ã¶nce bu soruyu vektÃ¶rleÅŸtiriyor, sonra ChromaDB'de cosine similarity (kosinÃ¼s benzerliÄŸi) kullanarak en ilgili 3 kaynaÄŸÄ± buluyor. Bu arama yÃ¶ntemi, geleneksel kelime eÅŸleÅŸtirmesinden farklÄ± olarak metinlerin anlamÄ±na da bakÄ±yor.

4. **LLM ile Cevap OluÅŸturma:** Bulunan kaynaklar, GPT-4o-mini modeline context olarak gÃ¶nderiliyor ve kullanÄ±cÄ±nÄ±n sorusuna uygun bir cevap oluÅŸturuluyor. LangChain ve LangGraph kÃ¼tÃ¼phaneleri, bu sÃ¼reci yÃ¶netiyor ve AI agent'Ä±n kaynaklarÄ± doÄŸru ÅŸekilde kullanmasÄ±nÄ± saÄŸlÄ±yor.

## Mobil Uygulama (Frontend)

Mobil uygulama, **Flutter** framework'Ã¼ ile geliÅŸtirildi. **Dart** programlama dili kullanÄ±larak yazÄ±ldÄ± ve **Material Design 3** prensiplerine uygun olarak tasarlandÄ±. Uygulama, **RESTful API** ile backend ile iletiÅŸim kuruyor. KullanÄ±cÄ±lar:

- SorularÄ±nÄ± yazabiliyor
- CevaplarÄ± anlÄ±k olarak alabiliyor
- Kaynak linklerine tÄ±klayarak ilgili bÃ¶lÃ¼mlere gidebiliyor
- SharedPreferences ile yerel olarak saklanan Ã¶nceki konuÅŸmalarÄ±nÄ± gÃ¶rebiliyor

---

## RAG Pipeline: Ä°ÅŸleyiÅŸ SÃ¼reci

Sistem, **RAG (Retrieval Augmented Generation)** yaklaÅŸÄ±mÄ±nÄ± kullanarak Ã§alÄ±ÅŸÄ±yor. Bu sÃ¼reÃ§ ÅŸu adÄ±mlardan oluÅŸuyor:

1. **Indexing (Ä°ndeksleme):** TÃ¼m Ä°slami metinler JSON formatÄ±ndan okunuyor, text chunking ile parÃ§alara bÃ¶lÃ¼nÃ¼yor ve OpenAI embeddings API'si kullanÄ±larak vektÃ¶rleÅŸtiriliyor. Her chunk iÃ§in metadata (sure numarasÄ±, ayet numaralarÄ±, kaynak bilgisi) saklanÄ±yor.

2. **Query Processing:** KullanÄ±cÄ± sorduÄŸunda, soru da aynÄ± ÅŸekilde vektÃ¶rleÅŸtiriliyor.

3. **Retrieval:** ChromaDB'de similarity search yapÄ±larak en ilgili 3 dokÃ¼man bulunuyor. Bu iÅŸlem, cosine similarity metriÄŸi kullanÄ±larak gerÃ§ekleÅŸtiriliyor.

4. **Generation:** Bulunan kaynaklar, LangChain Ã¼zerinden GPT-4o-mini modeline context olarak gÃ¶nderiliyor. Model, bu kaynaklarÄ± kullanarak kullanÄ±cÄ±nÄ±n sorusuna cevap oluÅŸturuyor.

5. **Response:** Cevap, kaynak metadata'sÄ± ile birlikte kullanÄ±cÄ±ya dÃ¶ndÃ¼rÃ¼lÃ¼yor. Frontend'te, bu kaynaklar tÄ±klanabilir linkler olarak gÃ¶steriliyor.

---

**Technologies:** FastAPI, LangChain, Flutter, MySQL

